{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM/QYhmbygtQUo+5RCSglK7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greengerong/awesome-llm/blob/main/colab/Qwen_VL_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sszXFqvXj13-"
      },
      "outputs": [],
      "source": [
        "# https://github.com/QwenLM/Qwen-VL/tree/master\n",
        "%cd /content\n",
        "!git clone https://github.com/QwenLM/Qwen-VL.git\n",
        "%cd /content/Qwen-VL\n",
        "!pip install -r requirements.txt\n",
        "!pip install -r requirements_web_demo.txt\n",
        "!pip install accelerate\n",
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cli-demo"
      ],
      "metadata": {
        "id": "NjmUo1HlknPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers.generation import GenerationConfig\n",
        "import torch\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "\n",
        "# Note: The default behavior now has injection attack prevention off.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-VL-Chat\", trust_remote_code=True)\n",
        "\n",
        "# use bf16\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-VL-Chat\", device_map=\"auto\", trust_remote_code=True, bf16=True).eval()\n",
        "# use fp16\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-VL-Chat\", device_map=\"auto\", trust_remote_code=True, fp16=True).eval()\n",
        "# use cpu only\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-VL-Chat\", device_map=\"cpu\", trust_remote_code=True).eval()\n",
        "# use cuda device\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-VL-Chat\", device_map=\"cuda\", trust_remote_code=True).eval()\n",
        "\n",
        "# Specify hyperparameters for generation\n",
        "model.generation_config = GenerationConfig.from_pretrained(\"Qwen/Qwen-VL-Chat\", trust_remote_code=True)\n",
        "\n",
        "# 1st dialogue turn\n",
        "query = tokenizer.from_list_format([\n",
        "    {'image': 'https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg'}, # Either a local path or an url\n",
        "    {'text': '这是什么?'},\n",
        "])\n",
        "response, history = model.chat(tokenizer, query=query, history=None)\n",
        "print(response)\n",
        "# 图中是一名女子在沙滩上和狗玩耍，旁边是一只拉布拉多犬，它们处于沙滩上。\n",
        "\n",
        "# 2nd dialogue turn\n",
        "response, history = model.chat(tokenizer, '框出图中击掌的位置', history=history)\n",
        "print(response)\n",
        "# <ref>击掌</ref><box>(536,509),(588,602)</box>\n",
        "image = tokenizer.draw_bbox_on_latest_picture(response, history)\n",
        "if image:\n",
        "  image.save('1.jpg')\n",
        "else:\n",
        "  print(\"no box\")"
      ],
      "metadata": {
        "id": "7MwviLA9kpu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YvO8Mb-dox1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# web-demo"
      ],
      "metadata": {
        "id": "gL9s_mr0kvB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python web_demo_mm.py"
      ],
      "metadata": {
        "id": "CPIHQPG5kwqp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
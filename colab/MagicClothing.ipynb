{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO0WkOA15THbMOhmtU15L9o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greengerong/awesome-llm/blob/main/colab/MagicClothing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 环境"
      ],
      "metadata": {
        "id": "2YbcqJvwQjZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxCHUfTdQgeI",
        "outputId": "f7574d43-4893-4fa2-b115-f151213f9547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MagicClothing'...\n",
            "remote: Enumerating objects: 229, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 229 (delta 59), reused 53 (delta 31), pack-reused 138\u001b[K\n",
            "Receiving objects: 100% (229/229), 17.87 MiB | 20.44 MiB/s, done.\n",
            "Resolving deltas: 100% (107/107), done.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.9/261.9 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.0/161.0 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ShineChen1024/MagicClothing.git\n",
        "!pip install torch==2.0.1 torchvision==0.15.2 numpy==1.25.1 diffusers==0.25.1 opencv-python==4.9.0.80  transformers==4.31.0 gradio==4.16.0 safetensors==0.3.1 controlnet-aux==0.0.6 accelerate==0.21.0 -q -U\n",
        "!pip install -q insightface onnxruntime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 模型推理"
      ],
      "metadata": {
        "id": "C4sPAzuYQ6Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MagicClothing/checkpoints\n",
        "!wget https://huggingface.co/ShineChen1024/MagicClothing/resolve/main/oms_diffusion_768_120000.safetensors?download=true -O oms_diffusion_768_120000.safetensors\n",
        "!wget https://huggingface.co/ShineChen1024/MagicClothing/resolve/main/cloth_segm.pth?download=true -O cloth_segm.pth\n",
        "\n",
        "%cd /content/MagicClothing/checkpoints/ipadapter_faceid/\n",
        "!wget https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid_sd15_lora.safetensors?download=true -O ip-adapter-faceid_sd15_lora.safetensors\n",
        "!wget https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid_sd15.bin?download=true -O ip-adapter-faceid_sd15.bin\n",
        "!wget https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-plusv2_sd15_lora.safetensors?download=true -O ip-adapter-faceid-plusv2_sd15_lora.safetensors\n",
        "!wget https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-plusv2_sd15.bin?download=true -O ip-adapter-faceid-plusv2_sd15.bin\n",
        "!wget https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-plus_sd15_lora.safetensors?download=true -O ip-adapter-faceid-plus_sd15_lora.safetensors\n",
        "!wget https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-plus_sd15.bin?download=true -O ip-adapter-faceid-plus_sd15.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKO0hxexVIaA",
        "outputId": "b973ad96-0548-40e9-bcbf-1522e769e88c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MagicClothing/checkpoints/ipadapter_faceid\n",
            "--2024-04-01 15:05:37--  https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-plus_sd15.bin?download=true\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.17, 18.164.174.23, 18.164.174.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.huggingface.co/repos/36/ca/36ca54ff1895000df817b45a5ae71fccd14170b0843d8adc2ba7944d9ac903e9/252fb53e0d018489d9e7f9b9e2001a52ff700e491894011ada7cfb471e0fadf2?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27ip-adapter-faceid-plus_sd15.bin%3B+filename%3D%22ip-adapter-faceid-plus_sd15.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1712243137&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxMjI0MzEzN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzM2L2NhLzM2Y2E1NGZmMTg5NTAwMGRmODE3YjQ1YTVhZTcxZmNjZDE0MTcwYjA4NDNkOGFkYzJiYTc5NDRkOWFjOTAzZTkvMjUyZmI1M2UwZDAxODQ4OWQ5ZTdmOWI5ZTIwMDFhNTJmZjcwMGU0OTE4OTQwMTFhZGE3Y2ZiNDcxZTBmYWRmMj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=JdkGlD-v1XotdGgRhScmSN2%7Ey6mwMMpuV-YKj74lhCZT%7Efnc9B3fsVXAar2VxjG3cHgCMKC%7EzSizKk13wIBomv9DJLb79%7E1ISSI9YcHKVBDOdgx8dAb8wjBYYHOFlbIeY0lS%7EJRIHnQC8PG8%7EFSw8sIxlsj3fmUhHamQT2E9dsFSG6IDB%7ETwlxLhvu5ERj-4q-6NWceJYe1vSaJh2IKjHDHw75O3102Y5Ul6PPeOamrNtaY7C2FP3yo9KLd7cXUaOK0AEDFTjqBjWbfeyVlDOo5h0G5cAnp-AsxvZd46%7E%7EB1-N2km0e3yptPLmN9iLvFsxA4mdQ-eE1tsqIqE4ZUvA__&Key-Pair-Id=KCD77M1F0VK2B [following]\n",
            "--2024-04-01 15:05:37--  https://cdn-lfs-us-1.huggingface.co/repos/36/ca/36ca54ff1895000df817b45a5ae71fccd14170b0843d8adc2ba7944d9ac903e9/252fb53e0d018489d9e7f9b9e2001a52ff700e491894011ada7cfb471e0fadf2?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27ip-adapter-faceid-plus_sd15.bin%3B+filename%3D%22ip-adapter-faceid-plus_sd15.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1712243137&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxMjI0MzEzN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzM2L2NhLzM2Y2E1NGZmMTg5NTAwMGRmODE3YjQ1YTVhZTcxZmNjZDE0MTcwYjA4NDNkOGFkYzJiYTc5NDRkOWFjOTAzZTkvMjUyZmI1M2UwZDAxODQ4OWQ5ZTdmOWI5ZTIwMDFhNTJmZjcwMGU0OTE4OTQwMTFhZGE3Y2ZiNDcxZTBmYWRmMj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=JdkGlD-v1XotdGgRhScmSN2%7Ey6mwMMpuV-YKj74lhCZT%7Efnc9B3fsVXAar2VxjG3cHgCMKC%7EzSizKk13wIBomv9DJLb79%7E1ISSI9YcHKVBDOdgx8dAb8wjBYYHOFlbIeY0lS%7EJRIHnQC8PG8%7EFSw8sIxlsj3fmUhHamQT2E9dsFSG6IDB%7ETwlxLhvu5ERj-4q-6NWceJYe1vSaJh2IKjHDHw75O3102Y5Ul6PPeOamrNtaY7C2FP3yo9KLd7cXUaOK0AEDFTjqBjWbfeyVlDOo5h0G5cAnp-AsxvZd46%7E%7EB1-N2km0e3yptPLmN9iLvFsxA4mdQ-eE1tsqIqE4ZUvA__&Key-Pair-Id=KCD77M1F0VK2B\n",
            "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 18.65.25.64, 18.65.25.71, 18.65.25.119, ...\n",
            "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|18.65.25.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 156558503 (149M) [application/octet-stream]\n",
            "Saving to: ‘ip-adapter-faceid-plus_sd15.bin’\n",
            "\n",
            "ip-adapter-faceid-p 100%[===================>] 149.31M   279MB/s    in 0.5s    \n",
            "\n",
            "2024-04-01 15:05:38 (279 MB/s) - ‘ip-adapter-faceid-plus_sd15.bin’ saved [156558503/156558503]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 通用"
      ],
      "metadata": {
        "id": "I_xdFl2a718i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MagicClothing\n",
        "!python gradio_generate.py --model_path ./checkpoints/oms_diffusion_768_120000.safetensors --enable_cloth_guidance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nH4tX-d74xH",
        "outputId": "d33738a4-d4ef-4770-93ea-fd9e52e80c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MagicClothing\n",
            "2024-04-01 00:32:50.799085: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-01 00:32:50.799133: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-01 00:32:50.807001: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-01 00:32:52.735842: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading pipeline components...: 100% 5/5 [00:19<00:00,  3.99s/it]\n",
            "----checkpoints loaded from path: checkpoints/cloth_segm.pth----\n",
            "Running on local URL:  http://0.0.0.0:7860\n",
            "Running on public URL: https://6cd785f37ce0ee5acd.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "100% 20/20 [00:18<00:00,  1.08it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "100% 20/20 [00:17<00:00,  1.18it/s]\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2233, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/MagicClothing/gradio_generate.py\", line 61, in <module>\n",
            "    block.launch(server_name=\"0.0.0.0\", share=True, server_port=7860)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2140, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2235, in block_thread\n",
            "    print(\"Keyboard interruption in main thread... closing server.\")\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 0.0.0.0:7860 <> https://6cd785f37ce0ee5acd.gradio.live\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ipadapter_openpose"
      ],
      "metadata": {
        "id": "NKg2CvWpRZxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MagicClothing\n",
        "!python gradio_ipadapter_openpose.py --model_path ./checkpoints/oms_diffusion_768_120000.safetensors --enable_cloth_guidance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePV99Em0Q6la",
        "outputId": "0c4303c0-4016-42ba-b8e8-21279ece3a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MagicClothing\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
            "  warnings.warn(\n",
            "2024-04-01 15:05:52.696892: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-01 15:05:52.696943: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-01 15:05:52.702507: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-01 15:05:54.602396: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading pipeline components...: 100% 5/5 [00:18<00:00,  3.72s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/loaders/lora.py:1077: FutureWarning: `fuse_text_encoder_lora` is deprecated and will be removed in version 0.27. You are using an old version of LoRA backend. This will be deprecated in the next releases in favor of PEFT make sure to install the latest PEFT and transformers packages in the future.\n",
            "  deprecate(\"fuse_text_encoder_lora\", \"0.27\", LORA_DEPRECATION_MESSAGE)\n",
            "/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n",
            "----checkpoints loaded from path: checkpoints/cloth_segm.pth----\n",
            "Running on local URL:  http://0.0.0.0:7860\n",
            "Running on public URL: https://950c11e68338967c66.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 495, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1561, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1179, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 695, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/MagicClothing/gradio_ipadapter_openpose.py\", line 64, in process\n",
            "    result = ip_model.generate(cloth_image, face_img, cloth_mask_image, prompt, a_prompt, n_prompt, num_samples, seed, scale, cloth_guidance_scale, sample_steps, height, width, shortcut=v2, image=pose_image)\n",
            "  File \"/content/MagicClothing/garment_adapter/garment_ipadapter_faceid.py\", line 459, in generate\n",
            "    face_image = cv2.cvtColor(np.array(face_image), cv2.COLOR_RGB2BGR)\n",
            "cv2.error: OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
            "> Overload resolution failed:\n",
            ">  - src data type = object is not supported\n",
            ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "100% 20/20 [00:22<00:00,  1.12s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "100% 20/20 [00:21<00:00,  1.09s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "100% 20/20 [00:46<00:00,  2.33s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ipadapter_faceid"
      ],
      "metadata": {
        "id": "XFM4djqRRvWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MagicClothing\n",
        "!python gradio_ipadapter_faceid.py --model_path ./checkpoints/oms_diffusion_768_120000.safetensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1bEzGMIRvfp",
        "outputId": "788eb128-65dc-4d8a-f0c3-4aa42a3d781f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MagicClothing\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "2024-04-01 14:23:19.166872: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-01 14:23:19.166973: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-01 14:23:19.268343: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-01 14:23:21.447424: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "config.json: 100% 547/547 [00:00<00:00, 2.77MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 335M/335M [00:01<00:00, 223MB/s]\n",
            "model_index.json: 100% 609/609 [00:00<00:00, 3.07MB/s]\n",
            "Fetching 10 files:   0% 0/10 [00:00<?, ?it/s]\n",
            "tokenizer/special_tokens_map.json: 100% 472/472 [00:00<00:00, 2.57MB/s]\n",
            "\n",
            "text_encoder/config.json: 100% 612/612 [00:00<00:00, 3.93MB/s]\n",
            "\n",
            "tokenizer/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "tokenizer/tokenizer_config.json: 100% 737/737 [00:00<00:00, 5.29MB/s]\n",
            "\n",
            "\n",
            "unet/config.json: 100% 1.55k/1.55k [00:00<00:00, 11.3MB/s]\n",
            "\n",
            "\n",
            "tokenizer/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 2.63MB/s]\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   0% 0.00/3.44G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "scheduler/scheduler_config.json: 100% 548/548 [00:00<00:00, 2.94MB/s]\n",
            "Fetching 10 files:  20% 2/10 [00:00<00:03,  2.45it/s]\n",
            "\n",
            "tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 3.98MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 3.95MB/s]\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   1% 21.0M/3.44G [00:00<00:24, 140MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   4% 21.0M/492M [00:00<00:03, 134MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   1% 41.9M/3.44G [00:00<00:19, 170MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  11% 52.4M/492M [00:00<00:02, 190MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   2% 62.9M/3.44G [00:00<00:20, 167MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  15% 73.4M/492M [00:00<00:02, 180MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   2% 83.9M/3.44G [00:00<00:20, 163MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  19% 94.4M/492M [00:00<00:02, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   3% 105M/3.44G [00:00<00:22, 148MB/s] \u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  23% 115M/492M [00:00<00:02, 153MB/s] \u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   4% 126M/3.44G [00:00<00:23, 140MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  28% 136M/492M [00:00<00:02, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  32% 157M/492M [00:00<00:02, 162MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   4% 147M/3.44G [00:01<00:23, 138MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  36% 178M/492M [00:01<00:01, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   5% 168M/3.44G [00:01<00:22, 144MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  40% 199M/492M [00:01<00:01, 163MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   5% 189M/3.44G [00:01<00:22, 141MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  45% 220M/492M [00:01<00:01, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   6% 210M/3.44G [00:01<00:22, 146MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  49% 241M/492M [00:01<00:01, 165MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   7% 231M/3.44G [00:01<00:22, 145MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  53% 262M/492M [00:01<00:01, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   7% 252M/3.44G [00:01<00:21, 146MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  58% 283M/492M [00:01<00:01, 170MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   8% 273M/3.44G [00:01<00:21, 148MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  62% 304M/492M [00:01<00:01, 166MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  66% 325M/492M [00:01<00:00, 173MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   9% 294M/3.44G [00:01<00:21, 148MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   9% 315M/3.44G [00:02<00:20, 149MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  70% 346M/492M [00:02<00:00, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  10% 336M/3.44G [00:02<00:22, 138MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  75% 367M/492M [00:02<00:00, 146MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  79% 388M/492M [00:02<00:00, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  10% 357M/3.44G [00:02<00:23, 129MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  83% 409M/492M [00:02<00:00, 141MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  11% 377M/3.44G [00:02<00:24, 127MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  87% 430M/492M [00:02<00:00, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  12% 398M/3.44G [00:02<00:24, 125MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  92% 451M/492M [00:02<00:00, 135MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  12% 419M/3.44G [00:03<00:24, 125MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  96% 472M/492M [00:03<00:00, 128MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  13% 440M/3.44G [00:03<00:23, 128MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors: 100% 492M/492M [00:03<00:00, 128MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors: 100% 492M/492M [00:03<00:00, 148MB/s]\n",
            "Fetching 10 files:  40% 4/10 [00:04<00:06,  1.15s/it]\n",
            "diffusion_pytorch_model.safetensors:  14% 482M/3.44G [00:03<00:21, 138MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  15% 514M/3.44G [00:03<00:17, 164MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  16% 545M/3.44G [00:03<00:16, 177MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  17% 577M/3.44G [00:03<00:15, 189MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  18% 608M/3.44G [00:04<00:14, 199MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  19% 640M/3.44G [00:04<00:13, 203MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  20% 671M/3.44G [00:04<00:13, 208MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  20% 703M/3.44G [00:04<00:12, 213MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  21% 734M/3.44G [00:04<00:12, 208MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  22% 765M/3.44G [00:04<00:12, 213MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  23% 797M/3.44G [00:04<00:12, 219MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  24% 828M/3.44G [00:05<00:12, 217MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  25% 860M/3.44G [00:05<00:11, 225MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  26% 891M/3.44G [00:05<00:11, 222MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  27% 923M/3.44G [00:05<00:12, 206MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  27% 944M/3.44G [00:05<00:12, 198MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  28% 965M/3.44G [00:05<00:12, 195MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  29% 986M/3.44G [00:09<02:08, 19.1MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  29% 1.01G/3.44G [00:09<01:36, 25.2MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  30% 1.03G/3.44G [00:10<01:17, 31.2MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  31% 1.06G/3.44G [00:10<00:51, 46.4MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  31% 1.08G/3.44G [00:10<00:40, 58.0MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  32% 1.11G/3.44G [00:10<00:29, 80.0MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  33% 1.14G/3.44G [00:10<00:22, 101MB/s] \u001b[A\n",
            "diffusion_pytorch_model.safetensors:  34% 1.16G/3.44G [00:10<00:20, 113MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  34% 1.18G/3.44G [00:10<00:17, 128MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  35% 1.21G/3.44G [00:10<00:15, 140MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  36% 1.24G/3.44G [00:11<00:13, 163MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  37% 1.27G/3.44G [00:11<00:11, 182MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  38% 1.30G/3.44G [00:11<00:10, 198MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  39% 1.33G/3.44G [00:11<00:10, 206MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  40% 1.36G/3.44G [00:11<00:09, 217MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  41% 1.39G/3.44G [00:11<00:08, 227MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  41% 1.43G/3.44G [00:11<00:09, 218MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  42% 1.46G/3.44G [00:12<00:13, 150MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  43% 1.48G/3.44G [00:12<00:12, 160MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  44% 1.50G/3.44G [00:12<00:11, 170MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  45% 1.53G/3.44G [00:12<00:10, 181MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  45% 1.56G/3.44G [00:12<00:09, 194MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  46% 1.59G/3.44G [00:12<00:08, 205MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  47% 1.63G/3.44G [00:12<00:08, 210MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  48% 1.66G/3.44G [00:13<00:08, 220MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  49% 1.69G/3.44G [00:13<00:07, 223MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  50% 1.72G/3.44G [00:13<00:07, 233MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  51% 1.75G/3.44G [00:13<00:07, 228MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  52% 1.78G/3.44G [00:13<00:07, 236MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  53% 1.81G/3.44G [00:13<00:06, 242MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  54% 1.85G/3.44G [00:13<00:06, 236MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  55% 1.88G/3.44G [00:14<00:07, 214MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  56% 1.91G/3.44G [00:14<00:07, 215MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  56% 1.94G/3.44G [00:14<00:07, 213MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  57% 1.97G/3.44G [00:14<00:10, 143MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  58% 1.99G/3.44G [00:14<00:11, 131MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  59% 2.01G/3.44G [00:15<00:11, 129MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  59% 2.04G/3.44G [00:15<00:08, 155MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  60% 2.07G/3.44G [00:15<00:08, 163MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  61% 2.10G/3.44G [00:15<00:07, 183MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  62% 2.12G/3.44G [00:15<00:07, 172MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  63% 2.15G/3.44G [00:15<00:06, 187MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  63% 2.18G/3.44G [00:15<00:06, 200MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  64% 2.21G/3.44G [00:16<00:05, 212MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  65% 2.24G/3.44G [00:16<00:05, 218MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  66% 2.28G/3.44G [00:16<00:05, 226MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  67% 2.31G/3.44G [00:16<00:04, 228MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  68% 2.34G/3.44G [00:16<00:04, 235MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  69% 2.37G/3.44G [00:16<00:04, 223MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  70% 2.40G/3.44G [00:16<00:04, 227MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  71% 2.43G/3.44G [00:16<00:04, 222MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  72% 2.46G/3.44G [00:17<00:04, 219MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  73% 2.50G/3.44G [00:17<00:04, 198MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  73% 2.52G/3.44G [00:17<00:04, 188MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  74% 2.54G/3.44G [00:17<00:04, 190MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  74% 2.56G/3.44G [00:17<00:04, 186MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  75% 2.58G/3.44G [00:19<00:24, 34.5MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  76% 2.61G/3.44G [00:19<00:16, 50.0MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  77% 2.63G/3.44G [00:20<00:14, 56.6MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  77% 2.65G/3.44G [00:20<00:11, 69.8MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  78% 2.68G/3.44G [00:20<00:07, 94.3MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  79% 2.72G/3.44G [00:20<00:06, 119MB/s] \u001b[A\n",
            "diffusion_pytorch_model.safetensors:  80% 2.75G/3.44G [00:20<00:05, 138MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  81% 2.77G/3.44G [00:20<00:04, 146MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  81% 2.80G/3.44G [00:20<00:03, 163MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  82% 2.83G/3.44G [00:20<00:03, 179MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  83% 2.85G/3.44G [00:22<00:10, 58.1MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  84% 2.87G/3.44G [00:24<00:25, 22.3MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  84% 2.89G/3.44G [00:25<00:19, 27.7MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  85% 2.93G/3.44G [00:25<00:12, 40.9MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  86% 2.95G/3.44G [00:25<00:09, 51.4MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  86% 2.97G/3.44G [00:25<00:07, 64.4MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  87% 2.99G/3.44G [00:25<00:05, 78.8MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  88% 3.01G/3.44G [00:25<00:04, 94.2MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  88% 3.03G/3.44G [00:25<00:03, 104MB/s] \u001b[A\n",
            "diffusion_pytorch_model.safetensors:  89% 3.05G/3.44G [00:25<00:03, 120MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  90% 3.08G/3.44G [00:25<00:02, 144MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  90% 3.10G/3.44G [00:26<00:02, 158MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  91% 3.14G/3.44G [00:26<00:01, 176MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  92% 3.17G/3.44G [00:26<00:01, 195MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  93% 3.20G/3.44G [00:26<00:01, 211MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  94% 3.23G/3.44G [00:26<00:00, 222MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  95% 3.26G/3.44G [00:26<00:00, 216MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  96% 3.29G/3.44G [00:26<00:00, 207MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  97% 3.32G/3.44G [00:27<00:00, 207MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  98% 3.36G/3.44G [00:29<00:02, 34.3MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  98% 3.38G/3.44G [00:29<00:01, 41.8MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  99% 3.41G/3.44G [00:30<00:00, 56.2MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors: 100% 3.44G/3.44G [00:30<00:00, 113MB/s] \n",
            "Fetching 10 files: 100% 10/10 [00:31<00:00,  3.12s/it]\n",
            "Loading pipeline components...: 100% 5/5 [00:03<00:00,  1.44it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/loaders/lora.py:1077: FutureWarning: `fuse_text_encoder_lora` is deprecated and will be removed in version 0.27. You are using an old version of LoRA backend. This will be deprecated in the next releases in favor of PEFT make sure to install the latest PEFT and transformers packages in the future.\n",
            "  deprecate(\"fuse_text_encoder_lora\", \"0.27\", LORA_DEPRECATION_MESSAGE)\n",
            "config.json: 100% 4.72k/4.72k [00:00<00:00, 18.6MB/s]\n",
            "model.safetensors: 100% 3.94G/3.94G [00:56<00:00, 70.0MB/s]\n",
            "download_path: /root/.insightface/models/buffalo_l\n",
            "Downloading /root/.insightface/models/buffalo_l.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip...\n",
            "100% 281857/281857 [00:07<00:00, 36491.32KB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n",
            "----checkpoints loaded from path: checkpoints/cloth_segm.pth----\n",
            "Running on local URL:  http://0.0.0.0:7860\n",
            "Running on public URL: https://4857c3872555101542.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "100% 20/20 [00:13<00:00,  1.49it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "100% 20/20 [00:11<00:00,  1.68it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "100% 20/20 [00:12<00:00,  1.63it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "100% 20/20 [00:12<00:00,  1.60it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "100% 20/20 [00:25<00:00,  1.28s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "100% 20/20 [00:25<00:00,  1.25s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "100% 20/20 [00:25<00:00,  1.26s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 495, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1561, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1179, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 695, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/MagicClothing/gradio_ipadapter_faceid.py\", line 60, in process\n",
            "    result = ip_model.generate(cloth_image, face_img, cloth_mask_image, prompt, a_prompt, n_prompt, num_samples, seed, scale, cloth_guidance_scale, sample_steps, height, width, shortcut=v2)\n",
            "  File \"/content/MagicClothing/garment_adapter/garment_ipadapter_faceid.py\", line 471, in generate\n",
            "    cloth_mask = prepare_mask(cloth_mask_image, height, width)\n",
            "UnboundLocalError: local variable 'cloth_mask_image' referenced before assignment\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 495, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1561, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1179, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 695, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/MagicClothing/gradio_ipadapter_faceid.py\", line 60, in process\n",
            "    result = ip_model.generate(cloth_image, face_img, cloth_mask_image, prompt, a_prompt, n_prompt, num_samples, seed, scale, cloth_guidance_scale, sample_steps, height, width, shortcut=v2)\n",
            "  File \"/content/MagicClothing/garment_adapter/garment_ipadapter_faceid.py\", line 471, in generate\n",
            "    cloth_mask = prepare_mask(cloth_mask_image, height, width)\n",
            "UnboundLocalError: local variable 'cloth_mask_image' referenced before assignment\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "100% 20/20 [00:25<00:00,  1.26s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "100% 20/20 [00:25<00:00,  1.25s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "100% 20/20 [00:25<00:00,  1.25s/it]\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2233, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/MagicClothing/gradio_ipadapter_faceid.py\", line 97, in <module>\n",
            "    block.launch(server_name=\"0.0.0.0\",share=True,  server_port=7860)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2140, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2237, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/networking.py\", line 76, in close\n",
            "    self.thread.join()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 0.0.0.0:7860 <> https://4857c3872555101542.gradio.live\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOlxfzntP8nBqLErzHBVgz6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greengerong/awesome-llm/blob/main/colab/img/stable_cascade_web_ui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 环境设置"
      ],
      "metadata": {
        "id": "OymiLh5qaW2k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOXDQCdNaUZS"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "!pip install git+https://github.com/kashif/diffusers.git@wuerstchen-v3\n",
        "!pip install -U accelerate torch torchvision transformers\n",
        "!pip install gradio==4.17.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 推理(Web UI无需执行)"
      ],
      "metadata": {
        "id": "czeBdkrgaYjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableCascadeDecoderPipeline, StableCascadePriorPipeline\n",
        "\n",
        "num_images_per_prompt = 1\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "prior = StableCascadePriorPipeline.from_pretrained(\"stabilityai/stable-cascade-prior\", torch_dtype=torch.bfloat16)\n",
        "decoder = StableCascadeDecoderPipeline.from_pretrained(\"stabilityai/stable-cascade\", torch_dtype=torch.float16)\n",
        "# prior.enable_model_cpu_offload()\n",
        "prior.to(device)\n",
        "decoder.enable_model_cpu_offload()\n",
        "\n",
        "prompt = \"A cute cat model wearing a pink down jacket is showing off her yoga skills. She gracefully stands on her hind legs, with her front paws stretched out and her back paws lifted, as if doing a perfect downward dog pose. Her fur sparkles in the sun, radiating health and vitality.\"\n",
        "negative_prompt = \"\"\n",
        "\n",
        "prior_output = prior(\n",
        "    prompt=prompt,\n",
        "    height=1024,\n",
        "    width=1024,\n",
        "    negative_prompt=negative_prompt,\n",
        "    guidance_scale=4.0,\n",
        "    num_images_per_prompt=num_images_per_prompt,\n",
        "    num_inference_steps=20\n",
        ")\n",
        "decoder_output = decoder(\n",
        "    image_embeddings=prior_output.image_embeddings.half(),\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    guidance_scale=0.0,\n",
        "    output_type=\"pil\",\n",
        "    num_inference_steps=10\n",
        ").images\n",
        "\n",
        "decoder_output"
      ],
      "metadata": {
        "id": "3rNTBAsfaZSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web demo"
      ],
      "metadata": {
        "id": "-LH1CO3DcQnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型加载"
      ],
      "metadata": {
        "id": "ybiDIXlwcHnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableCascadeDecoderPipeline, StableCascadePriorPipeline\n",
        "device = torch.device(\"cuda\")\n",
        "prior = StableCascadePriorPipeline.from_pretrained(\"stabilityai/stable-cascade-prior\", torch_dtype=torch.bfloat16)\n",
        "decoder = StableCascadeDecoderPipeline.from_pretrained(\"stabilityai/stable-cascade\", torch_dtype=torch.float16)\n",
        "# prior.enable_model_cpu_offload()\n",
        "prior.to(device)\n",
        "decoder.enable_model_cpu_offload()"
      ],
      "metadata": {
        "id": "8LBYDSX7cIRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## web-ui"
      ],
      "metadata": {
        "id": "ucmMeiP5cTfm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNBbe-r53ina"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import gc\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "\n",
        "MAX_SEED = np.iinfo(np.int32).max\n",
        "MAX_IMAGE_SIZE = 1536\n",
        "\n",
        "\n",
        "def randomize_seed_fn(seed: int, randomize_seed: bool) -> int:\n",
        "    if randomize_seed:\n",
        "        seed = random.randint(0, MAX_SEED)\n",
        "    return seed\n",
        "\n",
        "def generate_prior(prompt, negative_prompt, generator, width, height, num_inference_steps, guidance_scale, num_images_per_prompt):\n",
        "  # prior.to(device=device)\n",
        "  prior_output = prior(\n",
        "      prompt=prompt,\n",
        "      height=height,\n",
        "      width=width,\n",
        "      negative_prompt=negative_prompt,\n",
        "      guidance_scale=guidance_scale,\n",
        "      num_images_per_prompt=num_images_per_prompt,\n",
        "      num_inference_steps=num_inference_steps\n",
        "  )\n",
        "  # prior.to(device=\"cpu\")\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "  return prior_output.image_embeddings\n",
        "\n",
        "\n",
        "def generate_decoder(prior_embeds, prompt, negative_prompt, generator, num_inference_steps, guidance_scale):\n",
        "\n",
        "  # decoder.to(device=device)\n",
        "  decoder_output = decoder(\n",
        "      image_embeddings=prior_embeds.to(device=device, dtype=decoder.dtype),\n",
        "      prompt=prompt,\n",
        "      negative_prompt=negative_prompt,\n",
        "      guidance_scale=guidance_scale,\n",
        "      output_type=\"pil\",\n",
        "      num_inference_steps=num_inference_steps,\n",
        "      generator=generator\n",
        "  ).images\n",
        "  # decoder.to(device=\"cpu\")\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "  return decoder_output\n",
        "\n",
        "\n",
        "@torch.inference_mode()\n",
        "def generate(\n",
        "    prompt: str,\n",
        "    negative_prompt: str = \"\",\n",
        "    seed: int = 0,\n",
        "    randomize_seed: bool = True,\n",
        "    width: int = 1024,\n",
        "    height: int = 1024,\n",
        "    prior_num_inference_steps: int = 30,\n",
        "    prior_guidance_scale: float = 4.0,\n",
        "    decoder_num_inference_steps: int = 12,\n",
        "    decoder_guidance_scale: float = 0.0,\n",
        "    num_images_per_prompt: int = 2,\n",
        "):\n",
        "    \"\"\"Generate images using Stable Cascade.\"\"\"\n",
        "    seed = randomize_seed_fn(seed, randomize_seed)\n",
        "    print(\"seed:\", seed)\n",
        "    generator = torch.Generator(device=device).manual_seed(seed)\n",
        "    prior_embeds = generate_prior(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        generator=generator,\n",
        "        width=width,\n",
        "        height=height,\n",
        "        num_inference_steps=prior_num_inference_steps,\n",
        "        guidance_scale=prior_guidance_scale,\n",
        "        num_images_per_prompt=num_images_per_prompt,\n",
        "\n",
        "    )\n",
        "\n",
        "    decoder_output = generate_decoder(\n",
        "        prior_embeds=prior_embeds,\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        generator=generator,\n",
        "        num_inference_steps=decoder_num_inference_steps,\n",
        "        guidance_scale=decoder_guidance_scale,\n",
        "    )\n",
        "\n",
        "    return decoder_output\n",
        "\n",
        "\n",
        "examples = [\n",
        "    \"An astronaut riding a green horse\",\n",
        "    \"A mecha robot in a favela by Tarsila do Amaral\",\n",
        "    \"The sprirt of a Tamagotchi wandering in the city of Los Angeles\",\n",
        "    \"A delicious feijoada ramen dish\"\n",
        "]\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  with gr.Column():\n",
        "\n",
        "    prompt = gr.Text(\n",
        "        label=\"Prompt\",\n",
        "        show_label=False,\n",
        "        placeholder=\"Enter your prompt\",\n",
        "    )\n",
        "    run_button = gr.Button(\"Run\")\n",
        "    with gr.Accordion(\"Advanced options\", open=False):\n",
        "        negative_prompt = gr.Text(\n",
        "            label=\"Negative prompt\",\n",
        "            max_lines=1,\n",
        "            placeholder=\"Enter a Negative Prompt\",\n",
        "        )\n",
        "\n",
        "        seed = gr.Slider(\n",
        "            label=\"Seed\",\n",
        "            minimum=0,\n",
        "            maximum=MAX_SEED,\n",
        "            step=1,\n",
        "            value=0,\n",
        "        )\n",
        "        randomize_seed = gr.Checkbox(label=\"Randomize seed\", value=True)\n",
        "        width = gr.Slider(\n",
        "            label=\"Width\",\n",
        "            minimum=1024,\n",
        "            maximum=MAX_IMAGE_SIZE,\n",
        "            step=512,\n",
        "            value=1024,\n",
        "        )\n",
        "        height = gr.Slider(\n",
        "            label=\"Height\",\n",
        "            minimum=1024,\n",
        "            maximum=MAX_IMAGE_SIZE,\n",
        "            step=512,\n",
        "            value=1024,\n",
        "        )\n",
        "        num_images_per_prompt = gr.Slider(\n",
        "            label=\"Number of Images\",\n",
        "            minimum=1,\n",
        "            maximum=2,\n",
        "            step=1,\n",
        "            value=1,\n",
        "        )\n",
        "        prior_guidance_scale = gr.Slider(\n",
        "            label=\"Prior Guidance Scale\",\n",
        "            minimum=0,\n",
        "            maximum=20,\n",
        "            step=0.1,\n",
        "            value=4.0,\n",
        "        )\n",
        "        prior_num_inference_steps = gr.Slider(\n",
        "            label=\"Prior Inference Steps\",\n",
        "            minimum=10,\n",
        "            maximum=30,\n",
        "            step=1,\n",
        "            value=20,\n",
        "        )\n",
        "\n",
        "        decoder_guidance_scale = gr.Slider(\n",
        "            label=\"Decoder Guidance Scale\",\n",
        "            minimum=0,\n",
        "            maximum=0,\n",
        "            step=0.1,\n",
        "            value=0.0,\n",
        "        )\n",
        "        decoder_num_inference_steps = gr.Slider(\n",
        "            label=\"Decoder Inference Steps\",\n",
        "            minimum=4,\n",
        "            maximum=12,\n",
        "            step=1,\n",
        "            value=10,\n",
        "        )\n",
        "  with gr.Column():\n",
        "    result = gr.Gallery(label=\"Result\", show_label=False)\n",
        "\n",
        "  gr.Examples(\n",
        "      examples=examples,\n",
        "      inputs=prompt,\n",
        "      outputs=result,\n",
        "      fn=generate,\n",
        "  )\n",
        "\n",
        "  inputs = [\n",
        "          prompt,\n",
        "          negative_prompt,\n",
        "          seed,\n",
        "          randomize_seed,\n",
        "          width,\n",
        "          height,\n",
        "          prior_num_inference_steps,\n",
        "          prior_guidance_scale,\n",
        "          decoder_num_inference_steps,\n",
        "          decoder_guidance_scale,\n",
        "          num_images_per_prompt,\n",
        "  ]\n",
        "  prompt.submit(\n",
        "      fn=generate,\n",
        "      inputs=inputs,\n",
        "      outputs=result,\n",
        "  )\n",
        "  negative_prompt.submit(\n",
        "      fn=generate,\n",
        "      inputs=inputs,\n",
        "      outputs=result,\n",
        "  )\n",
        "  run_button.click(\n",
        "      fn=generate,\n",
        "      inputs=inputs,\n",
        "      outputs=result,\n",
        "  )\n",
        "\n",
        "  demo.launch(share=True, debug=True, show_error=True)\n",
        "\n"
      ]
    }
  ]
}
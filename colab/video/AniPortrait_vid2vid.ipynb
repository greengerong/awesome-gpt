{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greengerong/awesome-llm/blob/main/colab/video/AniPortrait_vid2vid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c871df98-65ac-4d97-bd69-8d4079ab2382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'AniPortrait'...\n",
            "remote: Enumerating objects: 149, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 149 (delta 29), reused 24 (delta 24), pack-reused 96\u001b[K\n",
            "Receiving objects: 100% (149/149), 53.86 MiB | 13.61 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n",
            "/content/AniPortrait\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  espeak-ng-data libaria2-0 libc-ares2 libespeak-ng1 libpcaudio0 libsonic0\n",
            "The following NEW packages will be installed:\n",
            "  aria2 espeak-ng espeak-ng-data libaria2-0 libc-ares2 libespeak-ng1 libpcaudio0 libsonic0\n",
            "0 upgraded, 8 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 6,038 kB of archives.\n",
            "After this operation, 17.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc-ares2 amd64 1.18.1-1ubuntu0.22.04.3 [45.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libaria2-0 amd64 1.36.0-1 [1,086 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 aria2 amd64 1.36.0-1 [381 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpcaudio0 amd64 1.1-6build2 [8,956 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsonic0 amd64 0.2.0-11build1 [10.3 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 espeak-ng-data amd64 1.50+dfsg-10 [3,956 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libespeak-ng1 amd64 1.50+dfsg-10 [207 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 espeak-ng amd64 1.50+dfsg-10 [343 kB]\n",
            "Fetched 6,038 kB in 3s (1,920 kB/s)\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../1-libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../2-aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Selecting previously unselected package libpcaudio0:amd64.\n",
            "Preparing to unpack .../3-libpcaudio0_1.1-6build2_amd64.deb ...\n",
            "Unpacking libpcaudio0:amd64 (1.1-6build2) ...\n",
            "Selecting previously unselected package libsonic0:amd64.\n",
            "Preparing to unpack .../4-libsonic0_0.2.0-11build1_amd64.deb ...\n",
            "Unpacking libsonic0:amd64 (0.2.0-11build1) ...\n",
            "Selecting previously unselected package espeak-ng-data:amd64.\n",
            "Preparing to unpack .../5-espeak-ng-data_1.50+dfsg-10_amd64.deb ...\n",
            "Unpacking espeak-ng-data:amd64 (1.50+dfsg-10) ...\n",
            "Selecting previously unselected package libespeak-ng1:amd64.\n",
            "Preparing to unpack .../6-libespeak-ng1_1.50+dfsg-10_amd64.deb ...\n",
            "Unpacking libespeak-ng1:amd64 (1.50+dfsg-10) ...\n",
            "Selecting previously unselected package espeak-ng.\n",
            "Preparing to unpack .../7-espeak-ng_1.50+dfsg-10_amd64.deb ...\n",
            "Unpacking espeak-ng (1.50+dfsg-10) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Setting up libpcaudio0:amd64 (1.1-6build2) ...\n",
            "Setting up libsonic0:amd64 (0.2.0-11build1) ...\n",
            "Setting up espeak-ng-data:amd64 (1.50+dfsg-10) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Setting up libespeak-ng1:amd64 (1.50+dfsg-10) ...\n",
            "Setting up espeak-ng (1.50+dfsg-10) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "e03014|\u001b[1;32mOK\u001b[0m  |   275MiB/s|/content/AniPortrait/pretrained_model/audio2mesh.pt\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "a54e85|\u001b[1;32mOK\u001b[0m  |   183MiB/s|/content/AniPortrait/pretrained_model/denoising_unet.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "962503|\u001b[1;32mOK\u001b[0m  |   252MiB/s|/content/AniPortrait/pretrained_model/motion_module.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "909e43|\u001b[1;32mOK\u001b[0m  |   274MiB/s|/content/AniPortrait/pretrained_model/pose_guider.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "c3f06e|\u001b[1;32mOK\u001b[0m  |   191MiB/s|/content/AniPortrait/pretrained_model/reference_unet.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "d820eb|\u001b[1;32mOK\u001b[0m  |   201MiB/s|/content/AniPortrait/pretrained_model/denoising_unet.1.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "ae97e2|\u001b[1;32mOK\u001b[0m  |   5.1MiB/s|/content/AniPortrait/pretrained_model/guidance_encoder_depth.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "908c2f|\u001b[1;32mOK\u001b[0m  |    20MiB/s|/content/AniPortrait/pretrained_model/guidance_encoder_dwpose.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "64873b|\u001b[1;32mOK\u001b[0m  |   163MiB/s|/content/AniPortrait/pretrained_model/guidance_encoder_normal.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "4a5c6d|\u001b[1;32mOK\u001b[0m  |    20MiB/s|/content/AniPortrait/pretrained_model/guidance_encoder_semantic_map.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "5c023e|\u001b[1;32mOK\u001b[0m  |       0B/s|/content/AniPortrait/pretrained_model/motion_module.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "cca514|\u001b[1;32mOK\u001b[0m  |   242MiB/s|/content/AniPortrait/pretrained_model/reference_unet.1.pth\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "e6537d|\u001b[1;32mOK\u001b[0m  |   114KiB/s|/content/AniPortrait/pretrained_model/image_encoder/config.json\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "1284ef|\u001b[1;32mOK\u001b[0m  |   223MiB/s|/content/AniPortrait/pretrained_model/image_encoder/pytorch_model.bin\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "2bccd5|\u001b[1;32mOK\u001b[0m  |    89KiB/s|/content/AniPortrait/pretrained_model/sd-vae-ft-mse/config.json\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "889e4a|\u001b[1;32mOK\u001b[0m  |   263MiB/s|/content/AniPortrait/pretrained_model/sd-vae-ft-mse/diffusion_pytorch_model.bin\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "2ee30c|\u001b[1;32mOK\u001b[0m  |    55KiB/s|/content/AniPortrait/pretrained_model/stable-diffusion-v1-5/feature_extractor/preprocessor_config.json\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "09302f|\u001b[1;32mOK\u001b[0m  |    88KiB/s|/content/AniPortrait/pretrained_model/stable-diffusion-v1-5/model_index.json\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "6fc9a2|\u001b[1;32mOK\u001b[0m  |   145KiB/s|/content/AniPortrait/pretrained_model/stable-diffusion-v1-5/unet/config.json\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "e00bf8|\u001b[1;32mOK\u001b[0m  |   170MiB/s|/content/AniPortrait/pretrained_model/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "3a6787|\u001b[1;32mOK\u001b[0m  |   304KiB/s|/content/AniPortrait/pretrained_model/stable-diffusion-v1-5/v1-inference.yaml\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "a314dd|\u001b[1;32mOK\u001b[0m  |   259KiB/s|/content/AniPortrait/pretrained_model/wav2vec2-base-960h/config.json\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "2deddb|\u001b[1;32mOK\u001b[0m  |    25KiB/s|/content/AniPortrait/pretrained_model/wav2vec2-base-960h/feature_extractor_config.json\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "16f0ce|\u001b[1;32mOK\u001b[0m  |    25KiB/s|/content/AniPortrait/pretrained_model/wav2vec2-base-960h/preprocessor_config.json\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "fdc542|\u001b[1;32mOK\u001b[0m  |   273MiB/s|/content/AniPortrait/pretrained_model/wav2vec2-base-960h/pytorch_model.bin\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "50f378|\u001b[1;32mOK\u001b[0m  |    13KiB/s|/content/AniPortrait/pretrained_model/wav2vec2-base-960h/special_tokens_map.json\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "da8206|\u001b[1;32mOK\u001b[0m  |    52MiB/s|/content/AniPortrait/pretrained_model/wav2vec2-base-960h/tf_model.h5\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "c519c9|\u001b[1;32mOK\u001b[0m  |    26KiB/s|/content/AniPortrait/pretrained_model/wav2vec2-base-960h/tokenizer_config.json\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "87357e|\u001b[1;32mOK\u001b[0m  |    47KiB/s|/content/AniPortrait/pretrained_model/wav2vec2-base-960h/vocab.json\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.5/222.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/AniPortrait\n",
        "%cd /content/AniPortrait\n",
        "\n",
        "!apt install espeak-ng aria2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AniPortrait/resolve/main/audio2mesh.pt -d /content/AniPortrait/pretrained_model -o audio2mesh.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AniPortrait/resolve/main/denoising_unet.pth -d /content/AniPortrait/pretrained_model -o denoising_unet.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AniPortrait/resolve/main/motion_module.pth -d /content/AniPortrait/pretrained_model -o motion_module.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AniPortrait/resolve/main/pose_guider.pth -d /content/AniPortrait/pretrained_model -o pose_guider.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AniPortrait/resolve/main/reference_unet.pth -d /content/AniPortrait/pretrained_model -o reference_unet.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/champ/denoising_unet.pth -d /content/AniPortrait/pretrained_model -o denoising_unet.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/champ/guidance_encoder_depth.pth -d /content/AniPortrait/pretrained_model -o guidance_encoder_depth.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/champ/guidance_encoder_dwpose.pth -d /content/AniPortrait/pretrained_model -o guidance_encoder_dwpose.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/champ/guidance_encoder_normal.pth -d /content/AniPortrait/pretrained_model -o guidance_encoder_normal.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/champ/guidance_encoder_semantic_map.pth -d /content/AniPortrait/pretrained_model -o guidance_encoder_semantic_map.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/champ/motion_module.pth -d /content/AniPortrait/pretrained_model -o motion_module.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/champ/reference_unet.pth -d /content/AniPortrait/pretrained_model -o reference_unet.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/raw/main/image_encoder/config.json -d /content/AniPortrait/pretrained_model/image_encoder -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/image_encoder/pytorch_model.bin -d /content/AniPortrait/pretrained_model/image_encoder -o pytorch_model.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/raw/main/sd-vae-ft-mse/config.json -d /content/AniPortrait/pretrained_model/sd-vae-ft-mse -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/sd-vae-ft-mse/diffusion_pytorch_model.bin -d /content/AniPortrait/pretrained_model/sd-vae-ft-mse -o diffusion_pytorch_model.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/raw/main/stable-diffusion-v1-5/feature_extractor/preprocessor_config.json -d /content/AniPortrait/pretrained_model/stable-diffusion-v1-5/feature_extractor -o preprocessor_config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/raw/main/stable-diffusion-v1-5/model_index.json -d /content/AniPortrait/pretrained_model/stable-diffusion-v1-5 -o model_index.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/raw/main/stable-diffusion-v1-5/unet/config.json -d /content/AniPortrait/pretrained_model/stable-diffusion-v1-5/unet -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin -d /content/AniPortrait/pretrained_model/stable-diffusion-v1-5/unet -o diffusion_pytorch_model.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/raw/main/stable-diffusion-v1-5/v1-inference.yaml -d /content/AniPortrait/pretrained_model/stable-diffusion-v1-5 -o v1-inference.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/raw/main/config.json -d /content/AniPortrait/pretrained_model/wav2vec2-base-960h -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/raw/main/feature_extractor_config.json -d /content/AniPortrait/pretrained_model/wav2vec2-base-960h -o feature_extractor_config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/raw/main/preprocessor_config.json -d /content/AniPortrait/pretrained_model/wav2vec2-base-960h -o preprocessor_config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/pytorch_model.bin -d /content/AniPortrait/pretrained_model/wav2vec2-base-960h -o pytorch_model.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/raw/main/special_tokens_map.json -d /content/AniPortrait/pretrained_model/wav2vec2-base-960h -o special_tokens_map.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tf_model.h5 -d /content/AniPortrait/pretrained_model/wav2vec2-base-960h -o tf_model.h5\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/raw/main/tokenizer_config.json -d /content/AniPortrait/pretrained_model/wav2vec2-base-960h -o tokenizer_config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/raw/main/vocab.json -d /content/AniPortrait/pretrained_model/wav2vec2-base-960h -o vocab.json\n",
        "\n",
        "!pip install -q imageio-ffmpeg==0.4.9 ffmpeg-python==0.2.0 av==11.0.0 omegaconf==2.2.3 diffusers==0.24.0 mediapipe==0.10.11 einops==0.4.1 accelerate==0.21.0 xformers==0.0.25 librosa==0.9.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zFZ-iCxYPmFA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eabd7572-d951-4d82-a7be-faa1d7319201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AniPortrait\n",
            "2024-04-26 12:12:46.820634: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-26 12:12:46.820684: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-26 12:12:46.905752: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-26 12:12:49.074012: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "Some weights of the model checkpoint were not used when initializing UNet2DConditionModel: \n",
            " ['conv_norm_out.weight, conv_norm_out.bias, conv_out.weight, conv_out.bias']\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1714133671.619675    6454 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:84) egl_initializedUnable to initialize EGL\n",
            "W0000 00:00:1714133671.663513    6454 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "I0000 00:00:1714133671.768867    6454 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:84) egl_initializedUnable to initialize EGL\n",
            "source video has 1202 frames, with 25 fps\n",
            "/content/AniPortrait/src/pipelines/pipeline_pose2vid_long.py:408: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet3DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet3DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
            "  num_channels_latents = self.denoising_unet.in_channels\n",
            "  4% 1/25 [02:55<1:10:23, 175.99s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/AniPortrait/scripts/vid2vid.py\", line 232, in <module>\n",
            "    main()\n",
            "  File \"/content/AniPortrait/scripts/vid2vid.py\", line 199, in main\n",
            "    video = pipe(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/AniPortrait/src/pipelines/pipeline_pose2vid_long.py\", line 537, in __call__\n",
            "    pred = self.denoising_unet(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/AniPortrait/src/models/unet_3d.py\", line 496, in forward\n",
            "    sample, res_samples = downsample_block(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/AniPortrait/src/models/unet_3d_blocks.py\", line 442, in forward\n",
            "    hidden_states = attn(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/AniPortrait/src/models/transformer_3d.py\", line 140, in forward\n",
            "    hidden_states = block(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/AniPortrait/src/models/mutual_self_attention.py\", line 179, in hacked_basic_transformer_inner_forward\n",
            "    self.attn1(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1507, in _wrapped_call_impl\n",
            "    def _wrapped_call_impl(self, *args, **kwargs):\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "%cd /content/AniPortrait\n",
        "!python -m scripts.vid2vid --config ./configs/prompts/animation_facereenac.yaml -W 512 -H 512 -L 256"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}